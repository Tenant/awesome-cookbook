# Dataset

[Large scale visual recognition challenge(ILSVRC)](http://image-net.org/challenges/LSVRC/)

[The UA-DETRAC Benchmark](https://detrac-db.rit.albany.edu/Tracking)

[NVIDIA AI CITY](https://www.aicitychallenge.org/)

## Object Detection

[CIFAR10 & 100](https://www.cs.toronto.edu/~kriz/cifar.html)



## Scene Segmentation

[CamVid](http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/)

CamVid是最早的第一用于自动驾驶领域的语义分割数据集，发布于2007年末。他们应用自己的图像标注软件在一段10分钟的视频中连续标注了700张图片，这些视频是由安装在汽车仪表盘的摄像机拍摄的，拍摄视角和司机的视角基本一致。



[KITTI](http://www.cvlibs.net/datasets/kitti/)

KITTI数据集发布于2012年，但是他们起初不标注好的语义分割图像，而是后来由另外的团队标注而成。然而这个数据集没有包括对[道路的标注](http://www.cvlibs.net/datasets/kitti/eval_road.php)。这个小数据集是由安装在车顶部的一系列传感器包括灰度传感器，彩色相机，雷达扫描仪和GPS/IMU单元拍摄而成。



[DUS](http://www.6d-vision.com/scene-labeling)

这个数据集包括5000灰度图像，其中只有500张标注过的语义分割图片。与其他数据集不同的是，它不包括“自然”这一分类。因为尺寸小，所以它比较适合用来测试语义分割模型的表现效果。

[CityScapes](https://www.cityscapes-dataset.com/)

它是DUS数据集的扩展版本，在更多的地形和气候条件下录制来获取更多变的城市景观。这个数据集也包括了很多粗糙的图片来提升大量弱标注的数据的表现效果。和DUS类似，相机是安装在挡风玻璃后面。图片中的30个类别也被分成了8个大类。这个数据集的一个特征就是它提供了20000多张粗分割的图片。很多深度学习技术应用这个传统的数据集来提升他们IoU评分。最近的模型一般IoU都在80%以上，一下链接包含了他们的打分系统还有实施准则。



[Vistas](https://blog.mapillary.com/product/2017/05/03/mapillary-vistas-dataset.html)



[BDD](http://bdd-data.berkeley.edu/)



[Apollo Scape](http://apolloscape.auto/scene.html)



# Lab



# Workshop

http://trajnet.stanford.edu/workshops/2018/








